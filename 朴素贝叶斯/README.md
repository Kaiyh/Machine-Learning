## 朴素贝叶斯

朴素贝叶斯是 _贝叶斯决策理论_ 的一部分。贝叶斯决策理论的核心思想是选择具有最高概率的决策。

我们称之为 "朴素"，是因为整个形式化过程只做最原始、最简单的假设：
1. 特征之间相互独立
2. 每个特征同等重要

## 朴素贝叶斯的思想

__根据某些先验概率计算样本变量属于某个类别的后验概率__ 。

> 条件概率公式：`P(c | w) = P(c & w) / P(w)`   
  贝叶斯准则：`P(c | w) = P(w | c) * P(c) / P(w)`

其中 `w` 为特征向量，`c` 为类别；`P(c | w)` 表示已知某特征向量 `w`，它属于某一类别 `c` 的概率，这是我们的计算目标；由贝叶斯公式可将后验概率 `P(c | w)` 转换为以下3个易于求得的先验概率：`P(w | c)`、`P(c)`、`P(w)`

1. 计算`P(c)`

通过类别c中的文档数除以总的文档数来计算概率 `P(c)`

2. 计算`P(w | c)`

这里利用朴素贝叶斯的第2个假设：因为每个特征之间相互独立，那么每个特征的概率直接相乘就可以得到总的概率。即：`P(w | c) = P(w1 | c) P(w2 | c) P(w3 | c) ... P(wn | c)`

注：剩下的一个概率`P(w)`的值恒等于1/n (n为总的文档数目)

代码详见：[bayes.py -> trainNB()](bayes.py)

## 使用条件概率进行分类

前面已经提到，贝叶斯决策理论的思想是选择具有最高概率的决策。

贝叶斯分类准则为：

    如果 P(c1 | w) > P(c2 | w)，那么属于类别c1
    如果 P(c1 | w) < P(c2 | w)，那么属于类别c2

代码详见：[bayes.py -> classifyNB()](bayes.py)

## 算法应用

I: 进行文本分类

思想：首先需要拆分文本，从文本中提取特征，这里的特征是文本中的 _词条_。处理的结果是把每一个文本片段表示为一个 _词条向量_，其中值为1表示词条出现在文本中，0表示未出现。

II: 过滤垃圾邮件

III: 从个人广告中获取区域倾向

代码详见：[bayes.py](bayes.py)