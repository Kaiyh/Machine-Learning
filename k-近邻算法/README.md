## k-近邻算法

英文是k-Nearest Neighbour，kNN

k-近邻算法采用测量不同特征值之间的距离方法进行分类。是监督学习中的一种分类算法，最简单的机器学习算法之一。

顾名思义，k-近邻算法就是要寻找距离给定的点最近的k个点，然后根据这k个点的分类信息来确定该点属于那一个类别。这里讲述的是广义的'点'，表示一条数据或称做一个样本，数据或样本包含多个特征，每个特征可以看做在多维空间中的点坐标。基于这种思想，我们可以用向量来描述数据，向量的每个分量对应一个特征。

## 工作原理

存在一个样本数据集合(训练样本集)，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据与所属分类的对应关系。

输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。

一般来说，我们只选择样本数据集中前k个最相似的数据，通常k是不大于20的整数。

最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。

## 算法步骤

0. 输入测试数据集，数据集中的每个点（数据）的类别属性均未知，则对每个点（数据）执行下述操作
1. 计算已知类别数据集中的点与当前点之间的距离
2. 按照距离递增次序排序
3. 选取与当前点距离最小的k个点
4. 确定前k个点所在类别的出现频率
5. 返回前k个点出现频率最高的类别作为当前点的预测分类

代码详见：[kNN.py -> classify0()](kNN.py)

## 算法应用

I:   划分平面上的点

II:  使用k-近邻算法改进约会网站的配对效果

III: 手写识别系统

代码详见 [kNN.py](kNN.py)